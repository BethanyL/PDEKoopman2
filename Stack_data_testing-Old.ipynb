{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "import glob, os\n",
    "import pickle\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User inputs\n",
    "data_name = 'Burgers_Eqn_exp28'  # Prefix of data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create numpy arrays with data\n",
    "\n",
    "# Use these lines to load all data\n",
    "data_test1 = np.load(('./data/%s_test1_x.npy' % data_name))\n",
    "data_test2 = np.load(('./data/%s_test2_x.npy' % data_name))\n",
    "data_test3 = np.load(('./data/%s_test3_x.npy' % data_name))\n",
    "data_test4 = np.load(('./data/%s_test4_x.npy' % data_name))\n",
    "data_test5 = np.load(('./data/%s_test5_x.npy' % data_name))\n",
    "data_test_all = np.vstack([data_test1,data_test2,data_test3,data_test4,data_test5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51000, 128)\n",
      "(255000, 128)\n"
     ]
    }
   ],
   "source": [
    "print(data_test1.shape)\n",
    "print(data_test_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import helperfns\n",
    "\n",
    "max_shifts_to_stack = 50\n",
    "len_time = 51\n",
    "data_test1_tensor = helperfns.stack_data(data_test1, max_shifts_to_stack, len_time)\n",
    "data_test2_tensor = helperfns.stack_data(data_test2, max_shifts_to_stack, len_time)\n",
    "data_test3_tensor = helperfns.stack_data(data_test3, max_shifts_to_stack, len_time)\n",
    "data_test4_tensor = helperfns.stack_data(data_test4, max_shifts_to_stack, len_time)\n",
    "data_test5_tensor = helperfns.stack_data(data_test5, max_shifts_to_stack, len_time)\n",
    "data_test_all_tensor = helperfns.stack_data(data_test_all, max_shifts_to_stack, len_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51, 1000, 128)\n",
      "(51, 5000, 128)\n"
     ]
    }
   ],
   "source": [
    "print(data_test1_tensor.shape)\n",
    "print(data_test_all_tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inputs to the network:\n",
    "\n",
    "Note: the data has shape: (len_time, num_examples, state_dimension)\n",
    "\n",
    "1. The 3D tensor with the data (no stacking required) - for autoencoder and outer autoencoder losses\n",
    "2. A 3D tensor for prediction: (len_time-num_shifts, num_examples, state_dimension)\n",
    "3. A 3D tensor for linearity loss: (len_time-num_shifts_middle, num_examples, state_dimension)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outputs of the network:\n",
    "\n",
    "1. The 3D tensor with the data - for autoencoder loss\n",
    "2. The 3D tensor with the predictions: (num_shifts, (len_time-num_shifts)*num_examples, state_dimension) \n",
    "3. The 3D tensor with the data - for outer autoencoder loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Internal Losses\n",
    "\n",
    "1. Inner autoencoder - Can do with the original data\n",
    "2. Linearity loss - Need to stack internally: match prediction but with num_shifts_middle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Strategy\n",
    "\n",
    "## Inputs to the network\n",
    "1. 3D tensor with shape (num_examples, len_time, state_dimension)\n",
    "\n",
    "## Outputs to the newtork\n",
    "1. 3D tensor with autoencoder output with shape (num_examples, len_time, state_dimension)\n",
    "2. 3D tensor with outer autoencoder output with shape (num_examples, len_time, state_dimension)\n",
    "3. 3D tensor with predictions with shape (num_shifts, (len_time-num_shifts)*num_examples, state_dimension)\n",
    "\n",
    "Does 3 need to change to (num_examples, num_shifts*(len_time-num_shifts), state_dimension)?\n",
    "\n",
    "## Internal Losses\n",
    "1. 3D tensor with inner autoencoder output with shape (num_examples, len_time, latent_dimension)\n",
    "2. 3D tensor with linearity predictions with shape (num_shifts_middle, (len_time-num_shifts_middle)*num_examples, latent_dimension)\n",
    "\n",
    "For 1, need to reshape back to 3D\n",
    "For 2, do we need to reshape like for predictions above?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.zeros(shape=(2,3,4))\n",
    "A[:,0,:] = np.array([[1,1,1,1],[2,2,2,2]])\n",
    "A[:,1,:] = np.array([[3,3,3,3],[4,4,4,4]])\n",
    "A[:,2,:] = np.array([[5,5,5,5],[6,6,6,6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1. 1. 1. 1.]\n",
      "  [3. 3. 3. 3.]\n",
      "  [5. 5. 5. 5.]]\n",
      "\n",
      " [[2. 2. 2. 2.]\n",
      "  [4. 4. 4. 4.]\n",
      "  [6. 6. 6. 6.]]]\n"
     ]
    }
   ],
   "source": [
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1. 1.]\n",
      " [2. 2. 2. 2.]\n",
      " [3. 3. 3. 3.]\n",
      " [4. 4. 4. 4.]\n",
      " [5. 5. 5. 5.]\n",
      " [6. 6. 6. 6.]]\n"
     ]
    }
   ],
   "source": [
    "print(np.reshape(A, (2*3,4), order='F'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "test_unstacked = np.reshape(data_test1_tensor, (51000, 128), order='F')\n",
    "print(np.linalg.norm(data_test1-test_unstacked))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "test_restacked = np.reshape(test_unstacked, (51, 1000, 128), order='F')\n",
    "print(np.linalg.norm(data_test1_tensor-test_restacked))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_stack_data(data, num_shifts, len_time):\n",
    "    nd = data.ndim\n",
    "    if nd > 1:\n",
    "        n = data.shape[1]\n",
    "    else:\n",
    "        data = (np.asmatrix(data)).getT()\n",
    "        n = 1\n",
    "    num_traj = data.shape[0] // len_time\n",
    "\n",
    "    new_len_time = len_time - num_shifts\n",
    "\n",
    "    data_tensor = np.zeros([num_shifts, num_traj * new_len_time, n])\n",
    "\n",
    "    for j in np.arange(num_shifts):\n",
    "        for count in np.arange(num_traj):\n",
    "            k = j+1\n",
    "            data_tensor_range = np.arange(count * new_len_time, new_len_time + count * new_len_time)\n",
    "            data_tensor[j, data_tensor_range, :] = data[count * len_time + k: count * len_time + k + new_len_time, :]\n",
    "\n",
    "    return data_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 41000, 128)\n"
     ]
    }
   ],
   "source": [
    "print(new_stack_data(data_test1, 10, 51).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Old version - second loop is no good\n",
    "\n",
    "#def stacked_predictions(data, num_shifts):\n",
    "#    len_pred = data.shape[0]-num_shifts\n",
    "#    prediction_tensor = np.zeros(shape=(num_shifts, len_pred*data.shape[1], data.shape[2]))\n",
    "#    for j in range(num_shifts):\n",
    "#        for ex_ind in range(data.shape[1]):\n",
    "#            prediction_tensor[j,ex_ind*len_pred:(ex_ind+1)*len_pred,:] = data[j+1:j+1+len_pred,ex_ind,:]\n",
    "#            \n",
    "#    return prediction_tensor\n",
    "        \n",
    "        \n",
    "        \n",
    "#data: (len_time, num_examples, state_dimension)        \n",
    "#prediction_tensor: (num_shifts, (len_time-num_shifts)*num_examples, state_dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 41000, 128)\n"
     ]
    }
   ],
   "source": [
    "print(stack_predictions(data_test1_tensor, 10).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "try1 = new_stack_data(data_test1, 50, 51)\n",
    "try2 = stack_predictions(data_test1_tensor, 50)\n",
    "#try2 = helperfns.stack_data(data_test1, 10, len_time)[:10,:,:]\n",
    "print(np.linalg.norm(try1-try2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 41000, 128)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "helperfns.stack_data(data_test1, 10, len_time).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_predictions(data, num_shifts):\n",
    "    len_pred = data.shape[0]-num_shifts\n",
    "    prediction_tensor = np.zeros(shape=(num_shifts, len_pred*data.shape[1], data.shape[2]))\n",
    "    for j in range(num_shifts):\n",
    "        prediction_tensor[j,:,:] = np.reshape(data[j+1:j+1+len_pred,:,:], \n",
    "                                              (len_pred*data.shape[1], data.shape[2]), \n",
    "                                              order='F')\n",
    "            \n",
    "    return prediction_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = stack_predictions(data_test1_tensor, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41000, 128)\n"
     ]
    }
   ],
   "source": [
    "data = data_test1_tensor\n",
    "num_shifts= 10\n",
    "len_time = 51\n",
    "pred_inputs = np.reshape(data[:len_time-num_shifts,:,:], ((len_time-num_shifts)*data.shape[1], data.shape[2]), order='F')\n",
    "print(pred_inputs.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41, 1000, 128)\n"
     ]
    }
   ],
   "source": [
    "# Prediction inputs?\n",
    "pred_inputs = data[:len_time-num_shifts,:,:]\n",
    "print(pred_inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_inputs(inputs):\n",
    "    input_list = []\n",
    "    for data in inputs:\n",
    "        input_list.append(np.reshape(data, \n",
    "                                     (data.shape[0]*data.shape[1], data.shape[2]),\n",
    "                                     order='F'))\n",
    "    return tuple(input_list)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51, 1000, 128)\n",
      "(41, 1000, 128)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "print(pred_inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51000, 128)\n",
      "(51000, 128)\n",
      "(41000, 128)\n"
     ]
    }
   ],
   "source": [
    "train_x = (data, data, pred_inputs)\n",
    "input1, input2, input3 = reshape_inputs(train_x)\n",
    "print(input1.shape)\n",
    "print(input2.shape)\n",
    "print(input3.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Something to consider - right now if num_shifts = 10 and len_time = 51, I only do prediction with the first 41 times in each trajectory (i.e. ones that can be shifted 10 times). However, I could shift the first 50 forward one time, the first 49 forward two times, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For the purposes of batches, I probably need to switch the first two indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51000, 128)\n",
      "(41000, 128)\n",
      "(36000, 128)\n",
      "(15, 21000, 128)\n"
     ]
    }
   ],
   "source": [
    "# Create the data inputs the old way:\n",
    "inputs = data_test1_tensor\n",
    "num_shifts = 10\n",
    "num_shifts_middle = 15\n",
    "\n",
    "pred_inputs = inputs[:len_time-num_shifts,:,:]\n",
    "lin_inputs = inputs[:len_time-num_shifts_middle,:,:]\n",
    "lin_exact = stack_predictions(lin_inputs, num_shifts_middle)\n",
    "auto_inputs, pred_inputs, lin_inputs = reshape_inputs((inputs, pred_inputs, lin_inputs))\n",
    "\n",
    "print(auto_inputs.shape)\n",
    "print(pred_inputs.shape)\n",
    "print(lin_inputs.shape)\n",
    "print(lin_exact.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 51, 128)\n"
     ]
    }
   ],
   "source": [
    "# Now try the new way\n",
    "inputs2 = np.transpose(inputs, (1,0,2))\n",
    "print(inputs2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_predictions(data, num_shifts):\n",
    "    len_pred = data.shape[1]-num_shifts\n",
    "    prediction_tensor = np.zeros(shape=(num_shifts, len_pred*data.shape[0], data.shape[2]))\n",
    "    for j in range(num_shifts):\n",
    "        prediction_tensor[j,:,:] = np.reshape(data[:,j+1:j+1+len_pred,:], \n",
    "                                              (len_pred*data.shape[0], data.shape[2]))\n",
    "            \n",
    "    return prediction_tensor\n",
    "\n",
    "def reshape_inputs(inputs):\n",
    "    input_list = []\n",
    "    for data in inputs:\n",
    "        input_list.append(np.reshape(data, \n",
    "                                     (data.shape[0]*data.shape[1], data.shape[2])))\n",
    "    return tuple(input_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51000, 128)\n",
      "(41000, 128)\n",
      "(36000, 128)\n",
      "(15, 21000, 128)\n"
     ]
    }
   ],
   "source": [
    "pred_inputs2 = inputs2[:,:len_time-num_shifts,:]\n",
    "lin_inputs2 = inputs2[:,:len_time-num_shifts_middle,:]\n",
    "lin_exact2 = stack_predictions(lin_inputs2, num_shifts_middle)\n",
    "auto_inputs2, pred_inputs2, lin_inputs2 = reshape_inputs((inputs2, pred_inputs2, lin_inputs2))\n",
    "\n",
    "print(auto_inputs2.shape)\n",
    "print(pred_inputs2.shape)\n",
    "print(lin_inputs2.shape)\n",
    "print(lin_exact2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(np.linalg.norm(auto_inputs-auto_inputs2))\n",
    "print(np.linalg.norm(pred_inputs-pred_inputs2))\n",
    "print(np.linalg.norm(lin_inputs-lin_inputs2))\n",
    "print(np.linalg.norm(lin_exact-lin_exact2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "test_reshape = np.reshape(auto_inputs2, inputs2.shape)\n",
    "print(np.linalg.norm(test_reshape-inputs2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try running code successfully with all np.reshape commands given full information, then try to reshape using the -1 in one dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = tf.reshape(inputs2, [-1, 128])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs3 = tf.convert_to_tensor(inputs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = tf.reshape(inputs3, [-1, 128])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82.89303214165567"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=0.0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.norm(test_input-auto_inputs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=int32, numpy=array([1000,   51,  128], dtype=int32)>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.shape(inputs3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1000, 51, 128])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.reshape(test_input, inputs3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1000, 51, 128])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51000, 128)\n",
      "(51000,)\n",
      "tf.Tensor(\n",
      "[ 0.86070107  3.18852999  4.56460334 ... 14.98881217 15.19485911\n",
      " 15.40130207], shape=(51000,), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "y_true = test_input\n",
    "denom_nonzero = 1e-5\n",
    "\n",
    "y_pred = test_input + .1\n",
    "print(y_true.shape)\n",
    "\n",
    "mse = tf.reduce_mean(tf.square(y_pred-y_true), axis=-1)\n",
    "true_norm = tf.reduce_mean(tf.square(y_true), axis=-1)\n",
    "# Ensure there are no 'zero' values in the denominator before division\n",
    "true_norm += denom_nonzero\n",
    "\n",
    "# Compute normalized MSE (normalized to true L2 norm)\n",
    "err = tf.truediv(mse, true_norm)\n",
    "\n",
    "print(err.shape)\n",
    "print(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 51, 128)\n",
      "(1000, 51)\n",
      "tf.Tensor(\n",
      "[[ 0.86070107  3.18852999  4.56460334 ... 27.96235219 28.24002683\n",
      "  28.51317275]\n",
      " [ 0.68413009  3.06583772  4.58510893 ... 52.67820085 53.59337338\n",
      "  54.50699705]\n",
      " [ 0.53546325  1.79974432  2.41768691 ... 11.51734396 11.59165787\n",
      "  11.66458119]\n",
      " ...\n",
      " [ 0.66238297  2.9862855   4.45629512 ... 32.47767376 33.19901964\n",
      "  33.92841306]\n",
      " [ 0.81281082  4.2845745   6.64892319 ... 46.02375358 46.87408073\n",
      "  47.72799107]\n",
      " [ 0.63134254  2.96784391  4.00191199 ... 14.98881217 15.19485911\n",
      "  15.40130207]], shape=(1000, 51), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "y_true = inputs3\n",
    "denom_nonzero = 1e-5\n",
    "\n",
    "y_pred = inputs3 + .1\n",
    "print(y_true.shape)\n",
    "\n",
    "mse = tf.reduce_mean(tf.square(y_pred-y_true), axis=-1)\n",
    "true_norm = tf.reduce_mean(tf.square(y_true), axis=-1)\n",
    "# Ensure there are no 'zero' values in the denominator before division\n",
    "true_norm += denom_nonzero\n",
    "\n",
    "# Compute normalized MSE (normalized to true L2 norm)\n",
    "err = tf.truediv(mse, true_norm)\n",
    "\n",
    "print(err.shape)\n",
    "print(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(51000,), dtype=float64, numpy=\n",
       "array([ 0.86070107,  3.18852999,  4.56460334, ..., 14.98881217,\n",
       "       15.19485911, 15.40130207])>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reshape(err, [-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=(3, 3) dtype=int32, numpy=\n",
      "array([[1, 2, 3],\n",
      "       [4, 5, 6],\n",
      "       [7, 8, 9]], dtype=int32)>\n"
     ]
    }
   ],
   "source": [
    "A = tf.Variable([[1,2,3],[4,5,6],[7,8,9]])\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
       "array([[1, 0, 0],\n",
       "       [0, 5, 0],\n",
       "       [0, 0, 9]], dtype=int32)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.linalg.diag(tf.linalg.diag_part(A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[1]*6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(255, 1000, 128)\n"
     ]
    }
   ],
   "source": [
    "data_test_tensor = data_test1_tensor\n",
    "data_test_tensor = np.vstack([data_test_tensor, data_test2_tensor])\n",
    "data_test_tensor = np.vstack([data_test_tensor, data_test3_tensor])\n",
    "data_test_tensor = np.vstack([data_test_tensor, data_test4_tensor])\n",
    "data_test_tensor = np.vstack([data_test_tensor, data_test5_tensor])\n",
    "print(data_test_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NODE2",
   "language": "python",
   "name": "node2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
